import os
import json
import torch
from torch.utils.data import Dataset
from pyquaternion import Quaternion
import numpy as np

import os
class LiDARGPTDataset(Dataset):
    def __init__(self, data_root, ann_file, n_points=10000, n_sweeps=10):
        """
        Khá»Ÿi táº¡o Dataset cho MiniGPT-3D sá»­ dá»¥ng dá»¯ liá»‡u nuScenes.

        Args:
            data_root (str): ÄÆ°á»ng dáº«n gá»‘c tá»›i folder chá»©a dá»¯ liá»‡u nuScenes (raw data).
                             VÃ­ dá»¥: '/data/nuscenes'
            ann_file (str): ÄÆ°á»ng dáº«n tá»›i file JSON metadata Ä‘Ã£ táº¡o á»Ÿ Giai Ä‘oáº¡n 1.
                            VÃ­ dá»¥: './unified_nuscenes_infos.json'
            n_points (int): Sá»‘ lÆ°á»£ng Ä‘iá»ƒm cá»‘ Ä‘á»‹nh cáº§n sample cho má»—i scene (Uni3D yÃªu cáº§u).
                            Máº·c Ä‘á»‹nh: 10,000.
            n_sweeps (int): Sá»‘ lÆ°á»£ng frame quÃ¡ khá»© cáº§n tÃ­ch lÅ©y.
                            Máº·c Ä‘á»‹nh: 10 (tÆ°Æ¡ng Ä‘Æ°Æ¡ng 0.5 giÃ¢y vá»›i LiDAR 20Hz).
        """
        super().__init__()
        
        # 1. LÆ°u cÃ¡c tham sá»‘ cáº¥u hÃ¬nh
        self.data_root = data_root
        self.n_points = n_points
        self.n_sweeps = n_sweeps

        # 2. Load dá»¯ liá»‡u Metadata (File JSON)
        if not os.path.exists(ann_file):
            raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y file metadata táº¡i: {ann_file}")
        
        print(f"ğŸ”„ Äang táº£i metadata tá»«: {ann_file}...")
        with open(ann_file, 'r') as f:
            self.data_infos = json.load(f)
        
        print(f"âœ… ÄÃ£ táº£i thÃ nh cÃ´ng {len(self.data_infos)} máº«u dá»¯ liá»‡u.")

        # 3. Äá»‹nh nghÄ©a Prompt Template chuáº©n cá»§a MiniGPT-3D
        # Token <PC>... lÃ  tÃ­n hiá»‡u Ä‘á»ƒ model biáº¿t vá»‹ trÃ­ chÃ¨n embedding 3D
        self.prompt_template = "<PC><PointCloudHere></PC> {}"

    def __len__(self):
        """Tráº£ vá» tá»•ng sá»‘ lÆ°á»£ng máº«u trong táº­p dá»¯ liá»‡u."""
        return len(self.data_infos)

    def load_pc(self, path):
        """ Äá»c file binary .bin cá»§a nuScenes.
        Input: ÄÆ°á»ng dáº«n file (tÆ°Æ¡ng Ä‘á»‘i).
        Output: Numpy array shape (N, 4) gá»“m [x, y, z, intensity].
        """
        full_path = os.path.join(self.data_root, path)
        if not os.path.exists(full_path):
            raise FileNotFoundError(f"File not found: {full_path}")

        # Äá»c binary float32
        points = np.fromfile(full_path, dtype=np.float32).reshape(-1, 5)
        
        # Chá»‰ láº¥y x, y, z, intensity (bá» ring_index á»Ÿ cá»™t 5)
        return points[:, :4]

    def accumulate_sweeps(self, index):
        """ TÃ­ch lÅ©y Ä‘iá»ƒm mÃ¢y tá»« cÃ¡c frame quÃ¡ khá»© (sweeps).
        ÄÃ¢y lÃ  ká»¹ thuáº­t quan trá»ng Ä‘á»ƒ lÃ m dÃ y dá»¯ liá»‡u LiDAR thÆ°a.
        """
        info = self.data_infos[index]
        
        # 1. Load frame hiá»‡n táº¡i (Keyframe)
        current_points = self.load_pc(info['lidar_path'])
        
        # ThÃªm kÃªnh thá»i gian (time_lag = 0 cho frame hiá»‡n táº¡i)
        # Shape: (N, 5) -> [x, y, z, intensity, time_lag]
        current_points = np.hstack([
            current_points, 
            np.zeros((current_points.shape[0], 1), dtype=np.float32)
        ])
        
        all_points_list = [current_points]
        
        # Láº¥y Pose cá»§a xe táº¡i thá»i Ä‘iá»ƒm hiá»‡n táº¡i (lÃ m gá»‘c)
        ref_pose = info['ego_pose']
        ref_trans = np.array(ref_pose['translation'])
        ref_rot = Quaternion(ref_pose['rotation'])
        
        # 2. Loop qua cÃ¡c frame quÃ¡ khá»©
        # LÆ°u Ã½: 'sweeps' trong json cáº§n Ä‘Æ°á»£c sáº¯p xáº¿p tá»« gáº§n nháº¥t Ä‘áº¿n xa nháº¥t
        if 'sweeps' in info:
            for i, sweep in enumerate(info['sweeps']):
                if i >= self.n_sweeps: break # Chá»‰ láº¥y n_sweeps frame
                
                # Load Ä‘iá»ƒm mÃ¢y cÅ©
                sweep_points = self.load_pc(sweep['lidar_path'])
                
                # --- CHUYá»‚N Há»† Tá»ŒA Äá»˜ ---
                sweep_pose = sweep['ego_pose']
                sweep_trans = np.array(sweep_pose['translation'])
                sweep_rot = Quaternion(sweep_pose['rotation'])
                
                # A. Sweep -> Global
                # CÃ´ng thá»©c: P_global = R_sweep * P_local + T_sweep
                points_xyz = sweep_points[:, :3]
                points_xyz = np.dot(points_xyz, sweep_rot.rotation_matrix.T) + sweep_trans
                
                # B. Global -> Current (Ref)
                # CÃ´ng thá»©c: P_current = R_ref.inverse * (P_global - T_ref)
                points_xyz = points_xyz - ref_trans
                points_xyz = np.dot(points_xyz, ref_rot.rotation_matrix) 
                
                # Cáº­p nháº­t láº¡i tá»a Ä‘á»™ xyz
                sweep_points[:, :3] = points_xyz
                
                # ThÃªm kÃªnh thá»i gian (time_lag)
                # Má»—i sweep cÃ¡ch nhau khoáº£ng 0.05s - 0.1s, ta dÃ¹ng index Ä‘á»ƒ Ä‘Ã¡nh dáº¥u
                time_lag = np.ones((sweep_points.shape[0], 1), dtype=np.float32) * (i + 1)
                sweep_points = np.hstack([sweep_points, time_lag])
                
                all_points_list.append(sweep_points)
        
        # Gá»™p táº¥t cáº£ láº¡i thÃ nh má»™t tensor lá»›n
        accumulated_points = np.concatenate(all_points_list, axis=0)
        return accumulated_points

    def filter_range(self, points):
        """
        Lá»c bá» cÃ¡c Ä‘iá»ƒm náº±m ngoÃ i pháº¡m vi quan tÃ¢m.
        GiÃºp loáº¡i bá» nhiá»…u á»Ÿ xa vÃ  giáº£m kÃ­ch thÆ°á»›c dá»¯ liá»‡u.
        """
        # Cáº¥u hÃ¬nh range (theo LiDAR-LLM/PointPillars): [-54m, 54m] cho X, Y
        # Z thÆ°á»ng láº¥y tá»« [-5m, 3m]
        x_min, x_max = -54.0, 54.0
        y_min, y_max = -54.0, 54.0
        z_min, z_max = -5.0, 3.0
        
        mask = (points[:, 0] >= x_min) & (points[:, 0] <= x_max) & \
               (points[:, 1] >= y_min) & (points[:, 1] <= y_max) & \
               (points[:, 2] >= z_min) & (points[:, 2] <= z_max)
               
        return points[mask]
    
    def uni3d_process(self, points):
        """
        BÆ°á»›c 10: Xá»­ lÃ½ hÃ¬nh há»c theo chuáº©n Uni3D Official Repo.
        Ref: minigpt4/datasets/datasets/object_point_dataset.py
        
        Input: Numpy array (N, C) tá»« bÆ°á»›c filter.
        Output: Numpy array (10000, 6) gá»“m [x, y, z, r, g, b].
        """
        # --- A. Sampling (Báº¯t buá»™c vÃ¬ nuScenes raw cÃ³ sá»‘ Ä‘iá»ƒm thay Ä‘á»•i) ---
        # Uni3D yÃªu cáº§u cá»‘ Ä‘á»‹nh 10,000 Ä‘iá»ƒm.
        num_points = points.shape[0]
        
        if num_points == 0:
            # Fallback an toÃ n: tráº£ vá» array rá»—ng Ä‘Ãºng shape
            return np.zeros((self.n_points, 6), dtype=np.float32)

        if num_points >= self.n_points:
            # DÆ° Ä‘iá»ƒm -> Chá»n ngáº«u nhiÃªn khÃ´ng hoÃ n láº¡i (nhanh hÆ¡n FPS)
            choices = np.random.choice(num_points, self.n_points, replace=False)
        else:
            # Thiáº¿u Ä‘iá»ƒm -> Chá»n ngáº«u nhiÃªn cÃ³ hoÃ n láº¡i (Padding)
            choices = np.random.choice(num_points, self.n_points, replace=True)
        
        # Láº¥y xyz Ä‘Ã£ sample
        xyz = points[choices, :3] # Chá»‰ láº¥y 3 cá»™t Ä‘áº§u (XYZ), bá» intensity/time cÅ©

        # --- B. Normalization (Unit Sphere) ---
        # Theo code Uni3D: pc = (pc - mean) / max_norm
        centroid = np.mean(xyz, axis=0)
        xyz = xyz - centroid
        
        # TÃ­nh khoáº£ng cÃ¡ch Euclidean xa nháº¥t tá»« tÃ¢m
        m = np.max(np.sqrt(np.sum(xyz ** 2, axis=1)))
        
        # Guard: trÃ¡nh chia cho 0
        if m > 0:
            xyz = xyz / m

        # --- C. Input Channels (Quan trá»ng: ThÃªm RGB giáº£) ---
        # Uni3D encoder mong Ä‘á»£i Ä‘áº§u vÃ o 6 kÃªnh (XYZ + RGB).
        # Vá»›i dá»¯ liá»‡u khÃ´ng mÃ u (nhÆ° LiDAR), Uni3D fill giÃ¡ trá»‹ 0.4.
        rgb = np.ones_like(xyz) * 0.4
        
        # Gá»™p láº¡i thÃ nh tensor (10000, 6)
        points_6c = np.concatenate((xyz, rgb), axis=1)
            
        return points_6c 
    

    def __getitem__(self, index):
        """
        BÆ°á»›c 11, 12, 13: ÄÃ³ng gÃ³i dá»¯ liá»‡u Ä‘áº§u ra theo chuáº©n MiniGPT-3D.
        """
        # 1. Láº¥y thÃ´ng tin metadata
        item = self.data_infos[index]
        
        # --- Xá»¬ LÃ POINT CLOUD ---
        # A. TÃ­ch lÅ©y 10 frame (Logic nuScenes)
        # HÃ m nÃ y tráº£ vá» numpy array (N, 5)
        raw_points = self.accumulate_sweeps(index)
        
        # B. Lá»c nhiá»…u khÃ´ng gian
        # HÃ m nÃ y tráº£ vá» numpy array (M, 5)
        filtered_points = self.filter_range(raw_points)
        
        # C. Chuáº©n hÃ³a theo Uni3D (Quan trá»ng nháº¥t)
        # HÃ m nÃ y tráº£ vá» numpy array (10000, 6) gá»“m [x, y, z, 0.4, 0.4, 0.4]
        processed_points = self.uni3d_process(filtered_points)
        
        # D. Chuyá»ƒn sang Tensor
        pc_tensor = torch.from_numpy(processed_points.astype(np.float32))

        # --- Xá»¬ LÃ TEXT ---
        # Láº¥y instruction vÃ  answer tá»« file JSON Ä‘Ã£ chuáº©n bá»‹
        raw_instruction = item.get('instruction', "")
        raw_answer = item.get('answer', "")
        
        # E. Format Instruction (Theo tham kháº£o tá»« code gá»‘c)
        # Code gá»‘c cÃ³ bÆ°á»›c replace('<point>', '') vÃ  text_processor,
        # nhÆ°ng dá»¯ liá»‡u cá»§a ta lÃ  raw text sáº¡ch rá»“i nÃªn format trá»±c tiáº¿p.
        instruction_input = self.prompt_template.format(raw_instruction)

        # --- RETURN DICTIONARY ---
        # Output tráº£ vá» Ä‘Ãºng cÃ¡c key mÃ  MiniGPT-3D model yÃªu cáº§u trong forward()
        return {
            "pc": pc_tensor,                 # Tensor [10000, 6]
            "instruction_input": instruction_input, # "<PC><PointCloudHere></PC> Describe..."
            "answer": raw_answer,            # "There is a car..."
            "PC_id": item.get('sample_token', str(index)) # Token Ä‘á»ƒ tracking/debug
        }

if __name__ == "__main__":
    import sys
    
    # --- Cáº¤U HÃŒNH TEST ---
    # Thay Ä‘Æ°á»ng dáº«n nÃ y báº±ng Ä‘Æ°á»ng dáº«n tháº­t trÃªn mÃ¡y báº¡n Ä‘á»ƒ test
    # Náº¿u chÆ°a cÃ³ data tháº­t, code sáº½ bÃ¡o lá»—i FileNotFound nhÆ° mong Ä‘á»£i
    DATA_ROOT = "./data/nuscenes"
    ANN_FILE = "./unified_nuscenes_infos.json"
    
    print(f"ğŸš€ Báº¯t Ä‘áº§u Sanity Check...")
    print(f"ğŸ“‚ Data Root: {DATA_ROOT}")
    print(f"ğŸ“„ Ann File: {ANN_FILE}")

    # 1. Thá»­ khá»Ÿi táº¡o Dataset
    try:
        dataset = LiDARGPTDataset(
            data_root=DATA_ROOT,
            ann_file=ANN_FILE,
            n_points=10000,
            n_sweeps=10
        )
        print(f"âœ… Khá»Ÿi táº¡o thÃ nh cÃ´ng! Tá»•ng sá»‘ máº«u: {len(dataset)}")
    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi táº¡o: {e}")
        sys.exit(1)

    # 2. Láº¥y thá»­ máº«u Ä‘áº§u tiÃªn
    try:
        sample = dataset[0]
        pc = sample['pc']
        instr = sample['instruction_input']
        ans = sample['answer']
        token = sample['PC_id']

        print("\n--- ğŸ” Kiá»ƒm tra Máº«u sá»‘ 0 ---")
        print(f"ğŸ†” Token ID: {token}")
        
        # 3. Check Point Cloud Shape
        # Ká»³ vá»ng: [10000, 6] (XYZ + RGB giáº£)
        print(f"ğŸ“¦ PC Shape: {pc.shape}")
        if pc.shape == (10000, 6):
            print("   âœ… Shape chuáº©n (10k Ä‘iá»ƒm, 6 kÃªnh).")
        else:
            print(f"   âš ï¸ Cáº£nh bÃ¡o: Shape láº¡, ká»³ vá»ng (10000, 6).")

        # 4. Check Normalization
        # Ká»³ vá»ng: GiÃ¡ trá»‹ náº±m trong khoáº£ng [-1, 1] (hoáº·c lÃ¢n cáº­n)
        xyz = pc[:, :3]
        max_val = torch.max(xyz).item()
        min_val = torch.min(xyz).item()
        print(f"ğŸ“Š PC Range (XYZ): Min={min_val:.4f}, Max={max_val:.4f}")
        
        if -1.1 <= min_val and max_val <= 1.1:
            print("   âœ… Normalization cÃ³ váº» Ä‘Ãºng (náº±m trong Unit Sphere).")
        else:
            print("   âš ï¸ Cáº£nh bÃ¡o: GiÃ¡ trá»‹ vÆ°á»£t quÃ¡ [-1, 1], kiá»ƒm tra láº¡i logic normalize.")

        # 5. Check Instruction Format
        print(f"ğŸ“ Instruction: \"{instr}\"")
        if "<PC><PointCloudHere></PC>" in instr:
            print("   âœ… Format chuáº©n MiniGPT-3D.")
        else:
            print("   âŒ Lá»—i: Thiáº¿u tháº» <PC>... trong instruction!")

        print(f"ğŸ—£ï¸ Answer: \"{ans}\"")

        print("\nğŸ‰ CHÃšC Má»ªNG! Dataset Class hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh.")

    except Exception as e:
        print(f"\nâŒ Lá»—i khi láº¥y máº«u: {e}")
        import traceback
        traceback.print_exc()

    try:
        import open3d as o3d
        print("\nğŸ¨ Äang hiá»ƒn thá»‹ Point Cloud (Cá»­a sá»• 3D sáº½ hiá»‡n ra)...")
        
        # Láº¥y xyz tá»« tensor
        xyz = pc[:, :3].numpy()
        
        # Táº¡o object Open3D
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(xyz)
        
        # ThÃªm trá»¥c tá»a Ä‘á»™ Ä‘á»ƒ dá»… nhÃ¬n (Red=X, Green=Y, Blue=Z)
        axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0, 0, 0])
        
        # Hiá»ƒn thá»‹
        o3d.visualization.draw_geometries([pcd, axes], window_name="Check Normalize")
        print("âœ… Visualize xong. Náº¿u tháº¥y Ä‘Ã¡m mÃ¢y Ä‘iá»ƒm hÃ¬nh cáº§u náº±m gá»n quanh gá»‘c tá»a Ä‘á»™ lÃ  Ä‘Ãºng!")
        
    except ImportError:
        print("âš ï¸ ChÆ°a cÃ i open3d nÃªn khÃ´ng visualize Ä‘Æ°á»£c. (pip install open3d)")
