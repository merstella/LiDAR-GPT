import os
import json
import torch
from torch.utils.data import Dataset
from pyquaternion import Quaternion
import numpy as np

import os
class LiDARGPTDataset(Dataset):
    def __init__(self, data_root, ann_file, n_points=10000, n_sweeps=10):
        """
        Khá»Ÿi táº¡o Dataset cho MiniGPT-3D sá»­ dá»¥ng dá»¯ liá»‡u nuScenes.

        Args:
            data_root (str): ÄÆ°á»ng dáº«n gá»‘c tá»›i folder chá»©a dá»¯ liá»‡u nuScenes (raw data).
                             VÃ­ dá»¥: '/data/nuscenes'
            ann_file (str): ÄÆ°á»ng dáº«n tá»›i file JSON metadata Ä‘Ã£ táº¡o á»Ÿ Giai Ä‘oáº¡n 1.
                            VÃ­ dá»¥: './unified_nuscenes_infos.json'
            n_points (int): Sá»‘ lÆ°á»£ng Ä‘iá»ƒm cá»‘ Ä‘á»‹nh cáº§n sample cho má»—i scene (Uni3D yÃªu cáº§u).
                            Máº·c Ä‘á»‹nh: 10,000.
            n_sweeps (int): Sá»‘ lÆ°á»£ng frame quÃ¡ khá»© cáº§n tÃ­ch lÅ©y.
                            Máº·c Ä‘á»‹nh: 10 (tÆ°Æ¡ng Ä‘Æ°Æ¡ng 0.5 giÃ¢y vá»›i LiDAR 20Hz).
        """
        super().__init__()
        
        # 1. LÆ°u cÃ¡c tham sá»‘ cáº¥u hÃ¬nh
        self.data_root = data_root
        self.n_points = n_points
        self.n_sweeps = n_sweeps

        # 2. Load dá»¯ liá»‡u Metadata (File JSON)
        if not os.path.exists(ann_file):
            raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y file metadata táº¡i: {ann_file}")
        
        print(f"Äang táº£i metadata tá»«: {ann_file}...")
        with open(ann_file, 'r') as f:
            self.data_infos = json.load(f)
        
        print(f"ÄÃ£ táº£i thÃ nh cÃ´ng {len(self.data_infos)} máº«u dá»¯ liá»‡u.")

        # 3. Äá»‹nh nghÄ©a Prompt Template chuáº©n cá»§a MiniGPT-3D
        # Token <PC>... lÃ  tÃ­n hiá»‡u Ä‘á»ƒ model biáº¿t vá»‹ trÃ­ chÃ¨n embedding 3D
        self.prompt_template = "<PC><PointCloudHere></PC> {}"

    def __len__(self):
        return len(self.data_infos)

    def load_pc(self, path):
        """ Äá»c file binary .bin cá»§a nuScenes.
        Input: ÄÆ°á»ng dáº«n file (tÆ°Æ¡ng Ä‘á»‘i).
        Output: Numpy array shape (N, 4) gá»“m [x, y, z, intensity].
        """
        full_path = os.path.join(self.data_root, path)
        if not os.path.exists(full_path):
            raise FileNotFoundError(f"File not found: {full_path}")
        
        # Äá»c binary float32
        points = np.fromfile(full_path, dtype=np.float32)
        points = points.reshape(-1, 5)
        # Chá»‰ láº¥y x, y, z, intensity (bá» ring_index á»Ÿ cá»™t 5)
        return points[:, :4]

    def get_matrix(self, pose):
        """HÃ m helper chuyá»ƒn translation/rotation thÃ nh ma tráº­n 4x4"""
        trans = np.array(pose['translation'])
        rot = Quaternion(pose['rotation']).rotation_matrix
        matrix = np.eye(4)
        matrix[:3, :3] = rot
        matrix[:3, 3] = trans
        return matrix
    
    def accumulate_sweeps(self, index):
        info = self.data_infos[index]
        
        # 1. Load Frame Hiá»‡n táº¡i (Reference)
        ref_points = self.load_pc(info['lidar_path'])
        # ThÃªm time_lag = 0
        ref_points = np.hstack([ref_points, np.zeros((ref_points.shape[0], 1), dtype=np.float32)])
        
        # --- CHUáº¨N Bá»Š MA TRáº¬N CHO REF FRAME ---
        # Ref Lidar -> Ref Ego
        ref_calib = info['calibrated_sensor']
        ref_lidar2ego = self.get_matrix(ref_calib)
        
        # Ref Ego -> Global
        ref_pose = info['ego_pose']
        ref_ego2global = self.get_matrix(ref_pose)
        
        # TÃ­nh ma tráº­n Ä‘áº£o: Global -> Ref Lidar 
        # (Global -> Ego -> Lidar) = inv(Ref Ego -> Global) * inv(Ref Lidar -> Ref Ego)
        ref_global2ego = np.linalg.inv(ref_ego2global)
        ref_ego2lidar = np.linalg.inv(ref_lidar2ego)
        
        # Gom láº¡i: Global -> Ref Lidar
        global2ref_lidar = np.dot(ref_ego2lidar, ref_global2ego)

        all_points_list = [ref_points]

        # 2. Loop Sweeps
        if 'sweeps' in info:
            for i, sweep in enumerate(info['sweeps']):
                if i >= self.n_sweeps: break
                
                sweep_points = self.load_pc(sweep['lidar_path'])
                if sweep_points.shape[0] == 0: continue
                
                # --- CHUYá»‚N Há»† Tá»ŒA Äá»˜ SWEEP ---
                # A. Sweep Lidar -> Sweep Ego
                sweep_calib = sweep['calibrated_sensor']
                sweep_lidar2ego = self.get_matrix(sweep_calib)
                
                # B. Sweep Ego -> Global
                sweep_pose = sweep['ego_pose']
                sweep_ego2global = self.get_matrix(sweep_pose)
                
                # C. Tá»•ng há»£p: Sweep Lidar -> Global
                sweep_lidar2global = np.dot(sweep_ego2global, sweep_lidar2ego)
                
                # D. Tá»•ng há»£p cuá»‘i cÃ¹ng: Sweep Lidar -> Ref Lidar
                # P_ref = (Global -> Ref Lidar) * (Sweep Lidar -> Global) * P_sweep
                transform_matrix = np.dot(global2ref_lidar, sweep_lidar2global)
                
                # Thá»±c hiá»‡n biáº¿n Ä‘á»•i nhÃ¢n ma tráº­n
                # Points: (N, 3) -> ThÃªm cá»™t 1 -> (N, 4) Ä‘á»ƒ nhÃ¢n vá»›i ma tráº­n 4x4
                points_xyz = sweep_points[:, :3]
                num_points = points_xyz.shape[0]
                points_homo = np.hstack([points_xyz, np.ones((num_points, 1))])
                
                # NhÃ¢n: (4, 4) . (4, N) -> (4, N) -> Transpose láº¡i thÃ nh (N, 4)
                points_transformed = np.dot(transform_matrix, points_homo.T).T
                
                # Cáº­p nháº­t láº¡i XYZ má»›i
                sweep_points[:, :3] = points_transformed[:, :3]
                
                # ThÃªm Time lag
                time_lag = np.ones((sweep_points.shape[0], 1), dtype=np.float32) * (i + 1)
                sweep_points = np.hstack([sweep_points, time_lag])
                
                all_points_list.append(sweep_points)
                
        return np.concatenate(all_points_list, axis=0)
    def filter_range(self, points):
        """
        Lá»c bá» cÃ¡c Ä‘iá»ƒm náº±m ngoÃ i pháº¡m vi quan tÃ¢m.
        GiÃºp loáº¡i bá» nhiá»…u á»Ÿ xa vÃ  giáº£m kÃ­ch thÆ°á»›c dá»¯ liá»‡u.
        """
        # Cáº¥u hÃ¬nh range (theo LiDAR-LLM/PointPillars): [-54m, 54m] cho X, Y
        # Z thÆ°á»ng láº¥y tá»« [-5m, 3m]
        x_min, x_max = -54.0, 54.0
        y_min, y_max = -54.0, 54.0
        z_min, z_max = -5.0, 3.0
        
        mask = (points[:, 0] >= x_min) & (points[:, 0] <= x_max) & \
               (points[:, 1] >= y_min) & (points[:, 1] <= y_max) & \
               (points[:, 2] >= z_min) & (points[:, 2] <= z_max)
               
        return points[mask]
    
    def uni3d_process(self, points):
        """
        Xá»­ lÃ½ hÃ¬nh há»c theo chuáº©n Uni3D
        
        Input: Numpy array (N, C) tá»« bÆ°á»›c filter.
        Output: Numpy array (10000, 6) gá»“m [x, y, z, r, g, b].
        """
        # --- A. Sampling (Báº¯t buá»™c vÃ¬ nuScenes raw cÃ³ sá»‘ Ä‘iá»ƒm thay Ä‘á»•i) ---
        # Uni3D yÃªu cáº§u cá»‘ Ä‘á»‹nh 10,000 Ä‘iá»ƒm.
        num_points = points.shape[0]
        
        if num_points == 0:
            # Fallback an toÃ n: tráº£ vá» array rá»—ng Ä‘Ãºng shape
            return np.zeros((self.n_points, 6), dtype=np.float32)

        if num_points >= self.n_points:
            # DÆ° Ä‘iá»ƒm -> Chá»n ngáº«u nhiÃªn khÃ´ng hoÃ n láº¡i (nhanh hÆ¡n FPS)
            choices = np.random.choice(num_points, self.n_points, replace=False)
        else:
            # Thiáº¿u Ä‘iá»ƒm -> Chá»n ngáº«u nhiÃªn cÃ³ hoÃ n láº¡i (Padding)
            choices = np.random.choice(num_points, self.n_points, replace=True)
        
        # Láº¥y xyz Ä‘Ã£ sample
        xyz = points[choices, :3] # Chá»‰ láº¥y 3 cá»™t Ä‘áº§u (XYZ), bá» intensity/time cÅ©

        # --- B. Normalization (Unit Sphere) ---
        # Theo code Uni3D: pc = (pc - mean) / max_norm
        centroid = np.mean(xyz, axis=0)
        xyz = xyz - centroid
        
        # TÃ­nh khoáº£ng cÃ¡ch Euclidean xa nháº¥t tá»« tÃ¢m
        m = np.max(np.sqrt(np.sum(xyz ** 2, axis=1)))
        
        # Guard: trÃ¡nh chia cho 0
        if m > 0:
            xyz = xyz / m

        # --- C. Input Channels (Quan trá»ng: ThÃªm RGB giáº£) ---
        # Uni3D encoder mong Ä‘á»£i Ä‘áº§u vÃ o 6 kÃªnh (XYZ + RGB).
        # Vá»›i dá»¯ liá»‡u khÃ´ng mÃ u (nhÆ° LiDAR), Uni3D fill giÃ¡ trá»‹ 0.4.
        rgb = np.ones_like(xyz) * 0.4
        
        # Gá»™p láº¡i thÃ nh tensor (10000, 6)
        points_6c = np.concatenate((xyz, rgb), axis=1)
            
        return points_6c 
    

    def __getitem__(self, index):
        """
        ÄÃ³ng gÃ³i dá»¯ liá»‡u Ä‘áº§u ra theo chuáº©n MiniGPT-3D.
        """
        # 1. Láº¥y thÃ´ng tin metadata
        item = self.data_infos[index]
        
        # --- Xá»¬ LÃ POINT CLOUD ---
        # A. TÃ­ch lÅ©y 10 frame (Logic nuScenes)
        # HÃ m nÃ y tráº£ vá» numpy array (N, 5)
        raw_points = self.accumulate_sweeps(index)
        
        # B. Lá»c nhiá»…u khÃ´ng gian
        # HÃ m nÃ y tráº£ vá» numpy array (M, 5)
        filtered_points = self.filter_range(raw_points)
        
        # C. Chuáº©n hÃ³a theo Uni3D (Quan trá»ng nháº¥t)
        # HÃ m nÃ y tráº£ vá» numpy array (10000, 6) gá»“m [x, y, z, 0.4, 0.4, 0.4]
        processed_points = self.uni3d_process(filtered_points)
        
        # D. Chuyá»ƒn sang Tensor
        pc_tensor = torch.from_numpy(processed_points.astype(np.float32))

        # --- Xá»¬ LÃ TEXT ---
        # Láº¥y instruction vÃ  answer tá»« file JSON Ä‘Ã£ chuáº©n bá»‹
        raw_instruction = item.get('instruction', "")
        raw_answer = item.get('answer', "")
        
        # E. Format Instruction 
        instruction_input = self.prompt_template.format(raw_instruction)

        # --- RETURN DICTIONARY ---
        # Output tráº£ vá» Ä‘Ãºng cÃ¡c key mÃ  MiniGPT-3D model yÃªu cáº§u trong forward()
        return {
            "pc": pc_tensor,                 # Tensor [10000, 6]
            "instruction_input": instruction_input, # "<PC><PointCloudHere></PC> Describe..."
            "answer": raw_answer,            # "There is a car..."
            "PC_id": item.get('sample_token', str(index)) # Token Ä‘á»ƒ tracking/debug
        }

if __name__ == "__main__":
    import sys
    
    # --- Cáº¤U HÃŒNH TEST ---
    # Thay Ä‘Æ°á»ng dáº«n nÃ y báº±ng Ä‘Æ°á»ng dáº«n tháº­t Ä‘á»ƒ test
    # Náº¿u chÆ°a cÃ³ data tháº­t, code sáº½ bÃ¡o lá»—i FileNotFound
    DATA_ROOT = "./data/nuscenes"
    ANN_FILE = "./unified_nuscenes_infos.json"
    
    print(f"ğŸš€ Báº¯t Ä‘áº§u Sanity Check...")
    print(f"ğŸ“‚ Data Root: {DATA_ROOT}")
    print(f"ğŸ“„ Ann File: {ANN_FILE}")

    # 1. Thá»­ khá»Ÿi táº¡o Dataset
    try:
        dataset = LiDARGPTDataset(
            data_root=DATA_ROOT,
            ann_file=ANN_FILE,
            n_points=10000,
            n_sweeps=10
        )
        print(f"âœ… Khá»Ÿi táº¡o thÃ nh cÃ´ng! Tá»•ng sá»‘ máº«u: {len(dataset)}")
    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi táº¡o: {e}")
        sys.exit(1)

    # 2. Láº¥y thá»­ máº«u Ä‘áº§u tiÃªn
    try:
        sample = dataset[0]
        pc = sample['pc']
        instr = sample['instruction_input']
        ans = sample['answer']
        token = sample['PC_id']

        print("\n--- ğŸ” Kiá»ƒm tra Máº«u sá»‘ 0 ---")
        print(f"ğŸ†” Token ID: {token}")
        
        # 3. Check Point Cloud Shape
        # Ká»³ vá»ng: [10000, 6] (XYZ + RGB giáº£)
        print(f"ğŸ“¦ PC Shape: {pc.shape}")
        if pc.shape == (10000, 6):
            print("   âœ… Shape chuáº©n (10k Ä‘iá»ƒm, 6 kÃªnh).")
        else:
            print(f"   âš ï¸ Cáº£nh bÃ¡o: Shape láº¡, ká»³ vá»ng (10000, 6).")

        # 4. Check Normalization
        # Ká»³ vá»ng: GiÃ¡ trá»‹ náº±m trong khoáº£ng [-1, 1] (hoáº·c lÃ¢n cáº­n)
        xyz = pc[:, :3]
        max_val = torch.max(xyz).item()
        min_val = torch.min(xyz).item()
        print(f"ğŸ“Š PC Range (XYZ): Min={min_val:.4f}, Max={max_val:.4f}")
        
        if -1.1 <= min_val and max_val <= 1.1:
            print("   âœ… Normalization cÃ³ váº» Ä‘Ãºng (náº±m trong Unit Sphere).")
        else:
            print("   âš ï¸ Cáº£nh bÃ¡o: GiÃ¡ trá»‹ vÆ°á»£t quÃ¡ [-1, 1], kiá»ƒm tra láº¡i logic normalize.")

        # 5. Check Instruction Format
        print(f"ğŸ“ Instruction: \"{instr}\"")
        if "<PC><PointCloudHere></PC>" in instr:
            print("   âœ… Format chuáº©n MiniGPT-3D.")
        else:
            print("   âŒ Lá»—i: Thiáº¿u tháº» <PC>... trong instruction!")

        print(f"ğŸ—£ï¸ Answer: \"{ans}\"")

        print("\nğŸ‰ CHÃšC Má»ªNG! Dataset Class hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh.")

    except Exception as e:
        print(f"\nâŒ Lá»—i khi láº¥y máº«u: {e}")
        import traceback
        traceback.print_exc()

    try:
        import open3d as o3d
        print("\nğŸ¨ Äang hiá»ƒn thá»‹ Point Cloud (Cá»­a sá»• 3D sáº½ hiá»‡n ra)...")
        
        # Láº¥y xyz tá»« tensor
        xyz = pc[:, :3].numpy()
        
        # Táº¡o object Open3D
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(xyz)
        
        # ThÃªm trá»¥c tá»a Ä‘á»™ Ä‘á»ƒ dá»… nhÃ¬n (Red=X, Green=Y, Blue=Z)
        axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0, 0, 0])
        
        # Hiá»ƒn thá»‹
        o3d.visualization.draw_geometries([pcd, axes], window_name="Check Normalize")
        print("âœ… Visualize xong. Náº¿u tháº¥y Ä‘Ã¡m mÃ¢y Ä‘iá»ƒm hÃ¬nh cáº§u náº±m gá»n quanh gá»‘c tá»a Ä‘á»™ lÃ  Ä‘Ãºng!")
        
    except ImportError:
        print("âš ï¸ ChÆ°a cÃ i open3d nÃªn khÃ´ng visualize Ä‘Æ°á»£c. (pip install open3d)")
