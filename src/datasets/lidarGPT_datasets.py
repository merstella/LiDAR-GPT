import os
import json
import torch
from torch.utils.data import Dataset
from pyquaternion import Quaternion
import numpy as np

import os
class LiDARGPTDataset(Dataset):
    def __init__(self, data_root, ann_file, n_points=10000, n_sweeps=10):
        """
        Khá»Ÿi táº¡o Dataset cho MiniGPT-3D sá»­ dá»¥ng dá»¯ liá»‡u nuScenes.
        sadfsdf
        Args:
            data_root (str): ÄÆ°á»ng dáº«n gá»‘c tá»›i folder chá»©a dá»¯ liá»‡u nuScenes (raw data).
                             VÃ­ dá»¥: '/data/nuscenes'
            ann_file (str): ÄÆ°á»ng dáº«n tá»›i file JSON metadata Ä‘Ã£ táº¡o á»Ÿ Giai Ä‘oáº¡n 1.
                            VÃ­ dá»¥: './unified_nuscenes_infos.json'
            n_points (int): Sá»‘ lÆ°á»£ng Ä‘iá»ƒm cá»‘ Ä‘á»‹nh cáº§n sample cho má»—i scene (Uni3D yÃªu cáº§u).
                            Máº·c Ä‘á»‹nh: 10,000.
            n_sweeps (int): Sá»‘ lÆ°á»£ng frame quÃ¡ khá»© cáº§n tÃ­ch lÅ©y.
                            Máº·c Ä‘á»‹nh: 10 (tÆ°Æ¡ng Ä‘Æ°Æ¡ng 0.5 giÃ¢y vá»›i LiDAR 20Hz).
        """
        super().__init__()
        
        # 1. LÆ°u cÃ¡c tham sá»‘ cáº¥u hÃ¬nh
        self.data_root = data_root
        self.n_points = n_points
        self.n_sweeps = n_sweeps

        # 2. Load dá»¯ liá»‡u Metadata (File JSON)
        if not os.path.exists(ann_file):
            raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y file metadata táº¡i: {ann_file}")
        
        print(f"Äang táº£i metadata tá»«: {ann_file}...")
        with open(ann_file, 'r') as f:
            self.data_infos = json.load(f)
        
        print(f"ÄÃ£ táº£i thÃ nh cÃ´ng {len(self.data_infos)} máº«u dá»¯ liá»‡u.")

        # 3. Äá»‹nh nghÄ©a Prompt Template chuáº©n cá»§a MiniGPT-3D
        # Token <PC>... lÃ  tÃ­n hiá»‡u Ä‘á»ƒ model biáº¿t vá»‹ trÃ­ chÃ¨n embedding 3D
        self.prompt_template = "<PC><PointCloudHere></PC> {}"

    def __len__(self):
        return len(self.data_infos)

    def load_pc(self, path):
        """ Äá»c file binary .bin cá»§a nuScenes.
        Input: ÄÆ°á»ng dáº«n file (tÆ°Æ¡ng Ä‘á»‘i).
        Output: Numpy array shape (N, 4) gá»“m [x, y, z, intensity].
        """
        full_path = os.path.join(self.data_root, path)
        if not os.path.exists(full_path):
            raise FileNotFoundError(f"File not found: {full_path}")
        
        # Äá»c binary float32
        points = np.fromfile(full_path, dtype=np.float32)
        points = points.reshape(-1, 5)
        # Chá»‰ láº¥y x, y, z, intensity (bá» ring_index á»Ÿ cá»™t 5)
        return points[:, :4]

    def get_matrix(self, pose):
        """HÃ m helper chuyá»ƒn translation/rotation thÃ nh ma tráº­n 4x4"""
        trans = np.array(pose['translation'])
        rot = Quaternion(pose['rotation']).rotation_matrix
        matrix = np.eye(4)
        matrix[:3, :3] = rot
        matrix[:3, 3] = trans
        return matrix
    
    def accumulate_sweeps(self, index):
        info = self.data_infos[index]
        
        # 1. Load Frame Hiá»‡n táº¡i (Reference)
        # ref_points shape: (N, 4) gá»“m [x, y, z, intensity]
        ref_points = self.load_pc(info['lidar_path']) 
        
        # --- CHUáº¨N Bá»Š MA TRáº¬N CHO REF FRAME (NGHá»ŠCH Äáº¢O) ---
        # Má»¥c tiÃªu: Táº¡o ma tráº­n chuyá»ƒn tá»« Global -> Ref Lidar
        # Logic: P_ref_lidar = inv(Ref_Lidar->Ref_Ego) * inv(Ref_Ego->Global) * P_global
        
        # Láº¥y thÃ´ng tin
        ref_calib = info['calibrated_sensor']
        ref_pose = info['ego_pose']
        
        # Táº¡o ma tráº­n thuáº­n
        ref_lidar2ego = self.get_matrix(ref_calib)
        ref_ego2global = self.get_matrix(ref_pose)
        
        # TÃ­nh ma tráº­n nghá»‹ch Ä‘áº£o
        ref_global2ego = np.linalg.inv(ref_ego2global)
        ref_ego2lidar = np.linalg.inv(ref_lidar2ego)
        
        # Gom láº¡i thÃ nh má»™t ma tráº­n duy nháº¥t: Global -> Ref Lidar
        global2ref_lidar = np.dot(ref_ego2lidar, ref_global2ego)
        
        all_points_list = [ref_points]

        # 2. Loop Sweeps (CÃ¡c frame quÃ¡ khá»©)
        if 'sweeps' in info:
            for i, sweep in enumerate(info['sweeps']):
                if i >= self.n_sweeps: break
                
                sweep_points = self.load_pc(sweep['lidar_path'])
                if sweep_points.shape[0] == 0: continue
                
                # --- CHUYá»‚N Há»† Tá»ŒA Äá»˜ SWEEP (THUáº¬N) ---
                # Má»¥c tiÃªu: Táº¡o ma tráº­n chuyá»ƒn tá»« Sweep Lidar -> Global
                # Logic: P_global = Sweep_Ego->Global * Sweep_Lidar->Sweep_Ego * P_sweep_lidar
                
                sweep_calib = sweep['calibrated_sensor']
                sweep_pose = sweep['ego_pose']
                
                sweep_lidar2ego = self.get_matrix(sweep_calib)
                sweep_ego2global = self.get_matrix(sweep_pose)
                
                # Gom láº¡i thÃ nh má»™t ma tráº­n duy nháº¥t: Sweep Lidar -> Global
                sweep_lidar2global = np.dot(sweep_ego2global, sweep_lidar2ego)
                
                # --- Tá»”NG Há»¢P: SWEEP LIDAR -> REF LIDAR ---
                # CÃ´ng thá»©c: P_ref = (Global -> Ref) * (Sweep -> Global) * P_sweep
                transform_matrix = np.dot(global2ref_lidar, sweep_lidar2global)
                
                # --- THá»°C HIá»†N NHÃ‚N MA TRáº¬N ---
                # 1. Láº¥y XYZ: (N, 3)
                points_xyz = sweep_points[:, :3]
                num_points = points_xyz.shape[0]
                
                # 2. Chuyá»ƒn sang tá»a Ä‘á»™ Ä‘á»“ng nháº¥t (Homogeneous coordinates): (N, 4)
                # ThÃªm cá»™t sá»‘ 1 vÃ o cuá»‘i: [x, y, z] -> [x, y, z, 1]
                points_homo = np.hstack([points_xyz, np.ones((num_points, 1))])
                
                # 3. NhÃ¢n ma tráº­n:
                # transform_matrix: (4, 4)
                # points_homo.T: (4, N) -> Chuyá»ƒn vá»‹ Ä‘á»ƒ nhÃ¢n cá»™t
                # Káº¿t quáº£ dot: (4, N)
                # .T cuá»‘i cÃ¹ng: Chuyá»ƒn vá»‹ ngÆ°á»£c láº¡i thÃ nh (N, 4)
                points_transformed = np.dot(transform_matrix, points_homo.T).T
                
                # 4. Cáº­p nháº­t láº¡i XYZ má»›i vÃ o sweep_points
                sweep_points[:, :3] = points_transformed[:, :3]
                
                
                all_points_list.append(sweep_points)
                
        return np.concatenate(all_points_list, axis=0)
    def filter_range(self, points):
        """
        Lá»c bá» cÃ¡c Ä‘iá»ƒm náº±m ngoÃ i pháº¡m vi quan tÃ¢m.
        GiÃºp loáº¡i bá» nhiá»…u á»Ÿ xa vÃ  giáº£m kÃ­ch thÆ°á»›c dá»¯ liá»‡u.
        """
        # Cáº¥u hÃ¬nh range (theo LiDAR-LLM/PointPillars): [-54m, 54m] cho X, Y
        # Z thÆ°á»ng láº¥y tá»« [-5m, 3m]
        x_min, x_max = -54.0, 54.0
        y_min, y_max = -54.0, 54.0
        z_min, z_max = -5.0, 3.0
        
        mask = (points[:, 0] >= x_min) & (points[:, 0] <= x_max) & \
               (points[:, 1] >= y_min) & (points[:, 1] <= y_max) & \
               (points[:, 2] >= z_min) & (points[:, 2] <= z_max)
               
        return points[mask]
    
    def uni3d_process(self, points):
        """
        Xá»­ lÃ½ hÃ¬nh há»c theo chuáº©n Uni3D
        
        Input: Numpy array (N, C) tá»« bÆ°á»›c filter.
        Output: Numpy array (10000, 6) gá»“m [x, y, z, r, g, b].
        """
        # --- A. Sampling (Báº¯t buá»™c vÃ¬ nuScenes raw cÃ³ sá»‘ Ä‘iá»ƒm thay Ä‘á»•i) ---
        # Uni3D yÃªu cáº§u cá»‘ Ä‘á»‹nh 10,000 Ä‘iá»ƒm.
        num_points = points.shape[0]
        
        if num_points == 0:
            # Fallback an toÃ n: tráº£ vá» array rá»—ng Ä‘Ãºng shape
            return np.zeros((self.n_points, 6), dtype=np.float32)

        if num_points >= self.n_points:
            # DÆ° Ä‘iá»ƒm -> Chá»n ngáº«u nhiÃªn khÃ´ng hoÃ n láº¡i (nhanh hÆ¡n FPS)
            choices = np.random.choice(num_points, self.n_points, replace=False)
        else:
            # Thiáº¿u Ä‘iá»ƒm -> Chá»n ngáº«u nhiÃªn cÃ³ hoÃ n láº¡i (Padding)
            choices = np.random.choice(num_points, self.n_points, replace=True)
        
        # Láº¥y xyz Ä‘Ã£ sample
        xyz = points[choices, :3] # Chá»‰ láº¥y 3 cá»™t Ä‘áº§u (XYZ), bá» intensity/time cÅ©

        # --- B. Normalization (Unit Sphere) ---
        # Theo code Uni3D: pc = (pc - mean) / max_norm
        centroid = np.mean(xyz, axis=0)
        xyz = xyz - centroid
        
        # TÃ­nh khoáº£ng cÃ¡ch Euclidean xa nháº¥t tá»« tÃ¢m
        m = np.max(np.sqrt(np.sum(xyz ** 2, axis=1)))
        
        # Guard: trÃ¡nh chia cho 0
        if m > 0:
            xyz = xyz / m

        # --- C. Input Channels (Quan trá»ng: ThÃªm RGB giáº£) ---
        # Uni3D encoder mong Ä‘á»£i Ä‘áº§u vÃ o 6 kÃªnh (XYZ + RGB).
        # Vá»›i dá»¯ liá»‡u khÃ´ng mÃ u (nhÆ° LiDAR), Uni3D fill giÃ¡ trá»‹ 0.4.
        rgb = np.ones_like(xyz) * 0.4
        
        # Gá»™p láº¡i thÃ nh tensor (10000, 6)
        points_6c = np.concatenate((xyz, rgb), axis=1)
            
        return points_6c 
    

    def __getitem__(self, index):
        """
        ÄÃ³ng gÃ³i dá»¯ liá»‡u Ä‘áº§u ra theo chuáº©n MiniGPT-3D.
        """
        # 1. Láº¥y thÃ´ng tin metadata
        item = self.data_infos[index]
        
        # --- Xá»¬ LÃ POINT CLOUD ---
        # A. TÃ­ch lÅ©y 10 frame (Logic nuScenes)
        # HÃ m nÃ y tráº£ vá» numpy array (N, 5)
        raw_points = self.accumulate_sweeps(index)
        
        # B. Lá»c nhiá»…u khÃ´ng gian
        # HÃ m nÃ y tráº£ vá» numpy array (M, 5)
        filtered_points = self.filter_range(raw_points)

        # C. Chuáº©n hÃ³a theo Uni3D (Quan trá»ng nháº¥t)
        # HÃ m nÃ y tráº£ vá» numpy array (10000, 6) gá»“m [x, y, z, 0.4, 0.4, 0.4]
        processed_points = self.uni3d_process(filtered_points)
        
        # D. Chuyá»ƒn sang Tensor
        pc_tensor = torch.from_numpy(processed_points.astype(np.float32))

        # --- Xá»¬ LÃ TEXT ---
        # Láº¥y instruction vÃ  answer tá»« file JSON Ä‘Ã£ chuáº©n bá»‹
        raw_instruction = item.get('instruction', "")
        raw_answer = item.get('answer', "")
        
        # E. Format Instruction 
        instruction_input = self.prompt_template.format(raw_instruction)

        # --- RETURN DICTIONARY ---
        # Output tráº£ vá» Ä‘Ãºng cÃ¡c key mÃ  MiniGPT-3D model yÃªu cáº§u trong forward()
        return {
            "pc": pc_tensor,                 # Tensor [10000, 6]
            "instruction_input": instruction_input, # "<PC><PointCloudHere></PC> Describe..."
            "answer": raw_answer,            # "There is a car..."
            "PC_id": item.get('sample_token', str(index)) # Token Ä‘á»ƒ tracking/debug
        }

if __name__ == "__main__":
    import sys
    
    # --- Cáº¤U HÃŒNH TEST ---
    # Thay Ä‘Æ°á»ng dáº«n nÃ y báº±ng Ä‘Æ°á»ng dáº«n tháº­t Ä‘á»ƒ test
    # Náº¿u chÆ°a cÃ³ data tháº­t, code sáº½ bÃ¡o lá»—i FileNotFound
    DATA_ROOT = "./data/nuscenes"
    ANN_FILE = "./unified_nuscenes_infos.json"
    
    print(f"ğŸš€ Báº¯t Ä‘áº§u Sanity Check...")
    print(f"ğŸ“‚ Data Root: {DATA_ROOT}")
    print(f"ğŸ“„ Ann File: {ANN_FILE}")

    # 1. Thá»­ khá»Ÿi táº¡o Dataset
    try:
        dataset = LiDARGPTDataset(
            data_root=DATA_ROOT,
            ann_file=ANN_FILE,
            n_points=10000,
            n_sweeps=3,
        )
        print(f"âœ… Khá»Ÿi táº¡o thÃ nh cÃ´ng! Tá»•ng sá»‘ máº«u: {len(dataset)}")
    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi táº¡o: {e}")
        sys.exit(1)

    try:
        # Thá»­ vá»›i n_sweeps=10 Ä‘á»ƒ kiá»ƒm tra accumulation
        dataset = LiDARGPTDataset(
            data_root=DATA_ROOT,
            ann_file=ANN_FILE,
            n_points=10000,
            n_sweeps=3,
        )
        print(f"âœ… Khá»Ÿi táº¡o thÃ nh cÃ´ng! Tá»•ng sá»‘ máº«u: {len(dataset)}")
    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi táº¡o: {e}")
        sys.exit(1)

    # 2. Láº¥y thá»­ máº«u Ä‘áº§u tiÃªn vÃ  Debug Visualize
    try:
        if len(dataset) > 0:
            # Chá»n index máº«u Ä‘á»ƒ kiá»ƒm tra (vÃ­ dá»¥ index 0)
            sample_idx = 0
            sample = dataset[sample_idx]
            
            # Láº¥y thÃ´ng tin metadata Ä‘á»ƒ in ra Ä‘Æ°á»ng dáº«n gá»‘c
            meta_info = dataset.data_infos[sample_idx]
            raw_lidar_path = os.path.join(DATA_ROOT, meta_info['lidar_path'])
            
            pc = sample['pc']
            instr = sample['instruction_input']
            ans = sample['answer']
            token = sample['PC_id']

            print(f"\n--- ğŸ” Kiá»ƒm tra Máº«u sá»‘ {sample_idx} ---")
            print(f"ğŸ†” Token ID: {token}")
            print(f"ğŸ“‚ Raw LiDAR Path: {raw_lidar_path}") # <-- In Ä‘Æ°á»ng dáº«n gá»‘c á»Ÿ Ä‘Ã¢y
            
            # 3. Check Point Cloud Shape
            print(f"ğŸ“¦ PC Shape: {pc.shape}")
            if pc.shape == (10000, 6):
                print("   âœ… Shape chuáº©n (10k Ä‘iá»ƒm, 6 kÃªnh).")
            else:
                print(f"   âš ï¸ Cáº£nh bÃ¡o: Shape láº¡, ká»³ vá»ng (10000, 6).")

            # 4. Check Normalization
            xyz = pc[:, :3]
            max_val = torch.max(xyz).item()
            min_val = torch.min(xyz).item()
            print(f"ğŸ“Š PC Range (XYZ): Min={min_val:.4f}, Max={max_val:.4f}")
            
            if -1.1 <= min_val and max_val <= 1.1:
                print("   âœ… Normalization cÃ³ váº» Ä‘Ãºng (náº±m trong Unit Sphere).")
            else:
                print("   âš ï¸ Cáº£nh bÃ¡o: GiÃ¡ trá»‹ vÆ°á»£t quÃ¡ [-1, 1], kiá»ƒm tra láº¡i logic normalize.")

            # 5. Check Instruction
            print(f"ğŸ“ Instruction: \"{instr}\"")
            if "<PC><PointCloudHere></PC>" in instr:
                print("   âœ… Format chuáº©n MiniGPT-3D.")
            
            print(f"ğŸ—£ï¸ Answer: \"{ans}\"")
            print("\nğŸ‰ CHÃšC Má»ªNG! Dataset Class hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh.")
            
            # --- OPEN3D VISUALIZATION ---
            try:
                import open3d as o3d
                print("\nğŸ¨ Äang hiá»ƒn thá»‹ Point Cloud (Cá»­a sá»• 3D sáº½ hiá»‡n ra)...")
                print(f"ğŸ‘‰ Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c load tá»« file gá»‘c: {meta_info['lidar_path']}")
                print(f"ğŸ‘‰ ÄÃ£ qua xá»­ lÃ½: Accumulate (10 sweeps) -> Filter Range -> Normalize")
                
                # Láº¥y xyz tá»« tensor
                xyz = pc[:, :3].numpy()
                
                # Táº¡o object Open3D
                pcd = o3d.geometry.PointCloud()
                pcd.points = o3d.utility.Vector3dVector(xyz)
                
                # ThÃªm trá»¥c tá»a Ä‘á»™ Ä‘á»ƒ dá»… nhÃ¬n (Red=X, Green=Y, Blue=Z)
                axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0, 0, 0])
                
                # Hiá»ƒn thá»‹
                o3d.visualization.draw_geometries([pcd, axes], window_name=f"Check Normalize - {token}")
                print("âœ… Visualize xong. Náº¿u tháº¥y Ä‘Ã¡m mÃ¢y Ä‘iá»ƒm hÃ¬nh cáº§u náº±m gá»n quanh gá»‘c tá»a Ä‘á»™ lÃ  Ä‘Ãºng!")
                
            except ImportError:
                print("âš ï¸ ChÆ°a cÃ i open3d nÃªn khÃ´ng visualize Ä‘Æ°á»£c. (pip install open3d)")
        else:
            print("Dataset rá»—ng! Kiá»ƒm tra láº¡i file json.")

    except Exception as e:
        print(f"\nâŒ Lá»—i khi láº¥y máº«u: {e}")
        import traceback
        traceback.print_exc()